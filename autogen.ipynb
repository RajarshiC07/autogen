{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import openai\n",
    "# Load environment variables from .env file\n",
    "from autogen import  AssistantAgent\n",
    "from autogen.agentchat.contrib.llamaindex_conversable_agent import LLamaIndexConversableAgent\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from autogen import ConversableAgent, UserProxyAgent\n",
    "from autogen.agentchat.contrib.capabilities import teachability\n",
    "from autogen import Cache\n",
    "from autogen.agentchat.contrib.capabilities.text_compressors import LLMLingua\n",
    "from autogen.agentchat.contrib.capabilities.transforms import TextMessageCompressor\n",
    "from autogen.agentchat.contrib.capabilities import transform_messages\n",
    "import autogen\n",
    "from autogen import ConversableAgent, UserProxyAgent\n",
    "from typing import Literal, Annotated\n",
    "load_dotenv()\n",
    "\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_list = [\n",
    "    {\n",
    "        \"model\":\"gpt-4\",\n",
    "        \"temperature\":0.9,\n",
    "        \"api_key\":openai_api_key\n",
    "    }\n",
    "]\n",
    "\n",
    "llm_config = {\n",
    "    \"config_list\": config_list,\n",
    "    \"timeout\": 120,\n",
    "}\n",
    "\n",
    "chatbot = autogen.AssistantAgent(\n",
    "    name=\"chatbot\",\n",
    "    system_message=\"For currency exchange tasks, only use the functions you have been provided with. Reply TERMINATE when the task is done.\",\n",
    "    llm_config=llm_config,\n",
    ")\n",
    "\n",
    "# create a UserProxyAgent instance named \"user_proxy\"\n",
    "user_proxy = autogen.ConversableAgent(\n",
    "    name=\"Human\",\n",
    "    llm_config=False,\n",
    "    human_input_mode='ALWAYS',\n",
    "    is_termination_msg=lambda msg: \"good bye\" in msg['content'] or None\n",
    ")\n",
    "\n",
    "\n",
    "CurrencySymbol = Literal[\"USD\", \"EUR\"]\n",
    "\n",
    "\n",
    "def exchange_rate(base_currency: CurrencySymbol, quote_currency: CurrencySymbol) -> float:\n",
    "    if base_currency == quote_currency:\n",
    "        return 1.0\n",
    "    elif base_currency == \"USD\" and quote_currency == \"EUR\":\n",
    "        return 1 / 1.1\n",
    "    elif base_currency == \"EUR\" and quote_currency == \"USD\":\n",
    "        return 1.1\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown currencies {base_currency}, {quote_currency}\")\n",
    "\n",
    "\n",
    "@user_proxy.register_for_execution()\n",
    "@chatbot.register_for_llm(description=\"Currency exchange calculator.\")\n",
    "def currency_calculator(\n",
    "    base_amount: Annotated[float, \"Amount of currency in base_currency\"],\n",
    "    base_currency: Annotated[CurrencySymbol, \"Base currency\"] = \"USD\",\n",
    "    quote_currency: Annotated[CurrencySymbol, \"Quote currency\"] = \"EUR\",\n",
    ") -> str:\n",
    "    quote_amount = exchange_rate(base_currency, quote_currency) * base_amount\n",
    "    return f\"{quote_amount} {quote_currency}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.currency_calculator(base_amount: Annotated[float, <autogen.tools.dependency_injection.Field object at 0x00000232D18E2570>], base_currency: Annotated[Literal['USD', 'EUR'], <autogen.tools.dependency_injection.Field object at 0x00000232D62534A0>] = 'USD', quote_currency: Annotated[Literal['USD', 'EUR'], <autogen.tools.dependency_injection.Field object at 0x00000232D62537D0>] = 'EUR') -> Any>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_proxy.function_map['currency_calculator']._origin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mHuman\u001b[0m (to chatbot):\n",
      "\n",
      "How much is 123.45 USD in EUR?\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mchatbot\u001b[0m (to Human):\n",
      "\n",
      "\u001b[32m***** Suggested tool call (call_GkXQJ4MbWOOcRC8Ujax7isOw): currency_calculator *****\u001b[0m\n",
      "Arguments: \n",
      "{\n",
      "  \"base_amount\": 123.45,\n",
      "  \"base_currency\": \"USD\",\n",
      "  \"quote_currency\": \"EUR\"\n",
      "}\n",
      "\u001b[32m************************************************************************************\u001b[0m\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mHuman\u001b[0m (to chatbot):\n",
      "\n",
      "hello\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mchatbot\u001b[0m (to Human):\n",
      "\n",
      "Hello! How can I assist you today?\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mHuman\u001b[0m (to chatbot):\n",
      "\n",
      "what is the converted rate?\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mchatbot\u001b[0m (to Human):\n",
      "\n",
      "\u001b[32m***** Suggested tool call (call_AC61AOeBQKlHgYzBheMSYM91): currency_calculator *****\u001b[0m\n",
      "Arguments: \n",
      "{\n",
      "  \"base_amount\": 1,\n",
      "  \"base_currency\": \"USD\",\n",
      "  \"quote_currency\": \"EUR\"\n",
      "}\n",
      "\u001b[32m************************************************************************************\u001b[0m\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "argument of type 'NoneType' is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Cache\u001b[38;5;241m.\u001b[39mdisk() \u001b[38;5;28;01mas\u001b[39;00m cache:\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;66;03m# start the conversation\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[43muser_proxy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minitiate_chat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchatbot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mHow much is 123.45 USD in EUR?\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msummary_method\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mreflection_with_llm\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\docs\\LLM_RAG_structureddata\\autogen\\.venv\\Lib\\site-packages\\autogen\\agentchat\\conversable_agent.py:1500\u001b[0m, in \u001b[0;36mConversableAgent.initiate_chat\u001b[1;34m(self, recipient, clear_history, silent, cache, max_turns, summary_method, summary_args, message, **kwargs)\u001b[0m\n\u001b[0;32m   1498\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1499\u001b[0m         msg2send \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgenerate_init_message(message, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m-> 1500\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmsg2send\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrecipient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msilent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msilent\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1501\u001b[0m summary \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_summarize_chat(\n\u001b[0;32m   1502\u001b[0m     summary_method,\n\u001b[0;32m   1503\u001b[0m     summary_args,\n\u001b[0;32m   1504\u001b[0m     recipient,\n\u001b[0;32m   1505\u001b[0m     cache\u001b[38;5;241m=\u001b[39mcache,\n\u001b[0;32m   1506\u001b[0m )\n\u001b[0;32m   1507\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m agent \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;28mself\u001b[39m, recipient]:\n",
      "File \u001b[1;32md:\\docs\\LLM_RAG_structureddata\\autogen\\.venv\\Lib\\site-packages\\autogen\\agentchat\\conversable_agent.py:1192\u001b[0m, in \u001b[0;36mConversableAgent.send\u001b[1;34m(self, message, recipient, request_reply, silent)\u001b[0m\n\u001b[0;32m   1190\u001b[0m valid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_append_oai_message(message, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124massistant\u001b[39m\u001b[38;5;124m\"\u001b[39m, recipient, is_sending\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m   1191\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m valid:\n\u001b[1;32m-> 1192\u001b[0m     \u001b[43mrecipient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreceive\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest_reply\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msilent\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1193\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1194\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1195\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMessage can\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt be converted into a valid ChatCompletion message. Either content or function_call must be provided.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1196\u001b[0m     )\n",
      "File \u001b[1;32md:\\docs\\LLM_RAG_structureddata\\autogen\\.venv\\Lib\\site-packages\\autogen\\agentchat\\conversable_agent.py:1302\u001b[0m, in \u001b[0;36mConversableAgent.receive\u001b[1;34m(self, message, sender, request_reply, silent)\u001b[0m\n\u001b[0;32m   1300\u001b[0m reply \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgenerate_reply(messages\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchat_messages[sender], sender\u001b[38;5;241m=\u001b[39msender)\n\u001b[0;32m   1301\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m reply \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1302\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreply\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msender\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msilent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msilent\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\docs\\LLM_RAG_structureddata\\autogen\\.venv\\Lib\\site-packages\\autogen\\agentchat\\conversable_agent.py:1192\u001b[0m, in \u001b[0;36mConversableAgent.send\u001b[1;34m(self, message, recipient, request_reply, silent)\u001b[0m\n\u001b[0;32m   1190\u001b[0m valid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_append_oai_message(message, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124massistant\u001b[39m\u001b[38;5;124m\"\u001b[39m, recipient, is_sending\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m   1191\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m valid:\n\u001b[1;32m-> 1192\u001b[0m     \u001b[43mrecipient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreceive\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest_reply\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msilent\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1193\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1194\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1195\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMessage can\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt be converted into a valid ChatCompletion message. Either content or function_call must be provided.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1196\u001b[0m     )\n",
      "File \u001b[1;32md:\\docs\\LLM_RAG_structureddata\\autogen\\.venv\\Lib\\site-packages\\autogen\\agentchat\\conversable_agent.py:1302\u001b[0m, in \u001b[0;36mConversableAgent.receive\u001b[1;34m(self, message, sender, request_reply, silent)\u001b[0m\n\u001b[0;32m   1300\u001b[0m reply \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgenerate_reply(messages\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchat_messages[sender], sender\u001b[38;5;241m=\u001b[39msender)\n\u001b[0;32m   1301\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m reply \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1302\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreply\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msender\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msilent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msilent\u001b[49m\u001b[43m)\u001b[49m\n",
      "    \u001b[1;31m[... skipping similar frames: ConversableAgent.send at line 1192 (3 times), ConversableAgent.receive at line 1302 (2 times)]\u001b[0m\n",
      "File \u001b[1;32md:\\docs\\LLM_RAG_structureddata\\autogen\\.venv\\Lib\\site-packages\\autogen\\agentchat\\conversable_agent.py:1302\u001b[0m, in \u001b[0;36mConversableAgent.receive\u001b[1;34m(self, message, sender, request_reply, silent)\u001b[0m\n\u001b[0;32m   1300\u001b[0m reply \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgenerate_reply(messages\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchat_messages[sender], sender\u001b[38;5;241m=\u001b[39msender)\n\u001b[0;32m   1301\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m reply \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1302\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreply\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msender\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msilent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msilent\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\docs\\LLM_RAG_structureddata\\autogen\\.venv\\Lib\\site-packages\\autogen\\agentchat\\conversable_agent.py:1192\u001b[0m, in \u001b[0;36mConversableAgent.send\u001b[1;34m(self, message, recipient, request_reply, silent)\u001b[0m\n\u001b[0;32m   1190\u001b[0m valid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_append_oai_message(message, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124massistant\u001b[39m\u001b[38;5;124m\"\u001b[39m, recipient, is_sending\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m   1191\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m valid:\n\u001b[1;32m-> 1192\u001b[0m     \u001b[43mrecipient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreceive\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest_reply\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msilent\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1193\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1194\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1195\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMessage can\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt be converted into a valid ChatCompletion message. Either content or function_call must be provided.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1196\u001b[0m     )\n",
      "File \u001b[1;32md:\\docs\\LLM_RAG_structureddata\\autogen\\.venv\\Lib\\site-packages\\autogen\\agentchat\\conversable_agent.py:1300\u001b[0m, in \u001b[0;36mConversableAgent.receive\u001b[1;34m(self, message, sender, request_reply, silent)\u001b[0m\n\u001b[0;32m   1298\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m request_reply \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m (request_reply \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreply_at_receive[sender] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m   1299\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m-> 1300\u001b[0m reply \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_reply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchat_messages\u001b[49m\u001b[43m[\u001b[49m\u001b[43msender\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msender\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msender\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1301\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m reply \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1302\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msend(reply, sender, silent\u001b[38;5;241m=\u001b[39msilent)\n",
      "File \u001b[1;32md:\\docs\\LLM_RAG_structureddata\\autogen\\.venv\\Lib\\site-packages\\autogen\\agentchat\\conversable_agent.py:2433\u001b[0m, in \u001b[0;36mConversableAgent.generate_reply\u001b[1;34m(self, messages, sender, **kwargs)\u001b[0m\n\u001b[0;32m   2431\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m   2432\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_match_trigger(reply_func_tuple[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrigger\u001b[39m\u001b[38;5;124m\"\u001b[39m], sender):\n\u001b[1;32m-> 2433\u001b[0m     final, reply \u001b[38;5;241m=\u001b[39m \u001b[43mreply_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msender\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msender\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreply_func_tuple\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mconfig\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2434\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m logging_enabled():\n\u001b[0;32m   2435\u001b[0m         log_event(\n\u001b[0;32m   2436\u001b[0m             \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   2437\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreply_func_executed\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2441\u001b[0m             reply\u001b[38;5;241m=\u001b[39mreply,\n\u001b[0;32m   2442\u001b[0m         )\n",
      "File \u001b[1;32md:\\docs\\LLM_RAG_structureddata\\autogen\\.venv\\Lib\\site-packages\\autogen\\agentchat\\conversable_agent.py:2191\u001b[0m, in \u001b[0;36mConversableAgent.check_termination_and_human_reply\u001b[1;34m(self, messages, sender, config)\u001b[0m\n\u001b[0;32m   2189\u001b[0m     no_human_input_msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNO HUMAN INPUT RECEIVED.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m reply \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2190\u001b[0m     \u001b[38;5;66;03m# if the human input is empty, and the message is a termination message, then we will terminate the conversation\u001b[39;00m\n\u001b[1;32m-> 2191\u001b[0m     reply \u001b[38;5;241m=\u001b[39m reply \u001b[38;5;28;01mif\u001b[39;00m reply \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_is_termination_msg\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessage\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexit\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2192\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   2193\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_consecutive_auto_reply_counter[sender] \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_max_consecutive_auto_reply_dict[sender]:\n",
      "Cell \u001b[1;32mIn[4], line 25\u001b[0m, in \u001b[0;36m<lambda>\u001b[1;34m(msg)\u001b[0m\n\u001b[0;32m     14\u001b[0m chatbot \u001b[38;5;241m=\u001b[39m autogen\u001b[38;5;241m.\u001b[39mAssistantAgent(\n\u001b[0;32m     15\u001b[0m     name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchatbot\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     16\u001b[0m     system_message\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFor currency exchange tasks, only use the functions you have been provided with. Reply TERMINATE when the task is done.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     17\u001b[0m     llm_config\u001b[38;5;241m=\u001b[39mllm_config,\n\u001b[0;32m     18\u001b[0m )\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# create a UserProxyAgent instance named \"user_proxy\"\u001b[39;00m\n\u001b[0;32m     21\u001b[0m user_proxy \u001b[38;5;241m=\u001b[39m autogen\u001b[38;5;241m.\u001b[39mConversableAgent(\n\u001b[0;32m     22\u001b[0m     name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHuman\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     23\u001b[0m     llm_config\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m     24\u001b[0m     human_input_mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mALWAYS\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m---> 25\u001b[0m     is_termination_msg\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m msg: \u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgood bye\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcontent\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     26\u001b[0m )\n\u001b[0;32m     29\u001b[0m CurrencySymbol \u001b[38;5;241m=\u001b[39m Literal[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUSD\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEUR\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mexchange_rate\u001b[39m(base_currency: CurrencySymbol, quote_currency: CurrencySymbol) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mfloat\u001b[39m:\n",
      "\u001b[1;31mTypeError\u001b[0m: argument of type 'NoneType' is not iterable"
     ]
    }
   ],
   "source": [
    "with Cache.disk() as cache:\n",
    "    # start the conversation\n",
    "    res = user_proxy.initiate_chat(\n",
    "        chatbot, message=\"How much is 123.45 USD in EUR?\", summary_method=\"reflection_with_llm\", cache=cache\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
